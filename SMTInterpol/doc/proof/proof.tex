\documentclass[a4paper]{article}
\usepackage{xspace}
\usepackage{relsize}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{pxfonts}
\usepackage{mathpartir}
\newcommand\mT{\mathcal{T}}
\newcommand\T{$\mT$\xspace}
\newcommand\Tp{$\mT'$\xspace}
\newcommand\mtp{\models_{\mT'}}
\newcommand\syms{\mathop{\mathit{syms}}}
\newcommand\si{SMTInterpol\xspace}
\newcommand\sversion{2.0}
\newcommand\siv{\si~\sversion}
\newcommand\gen[1]{\mathop{gen}\nolimits_{#1}}
\newcommand\dom{\mathop{dom}}
\newcommand\todo[1]{\textcolor{red}{TODO: #1}}
\newcommand\seqcomp{\circledwedge}
\newcommand\choicecomp{\circledvee}
\newcommand\smtlib[1]{\texttt{#1}}

%canonical form
\newcommand\cf{\mathit{cf}}
\newcommand\annot[2]{(!\ #1\ \texttt{#2})}

\title{Proofs in SMTInterpol}
\author{J{\"u}rgen Christ \and Jochen Hoenicke}
\date{2022/07/09}
\begin{document}
\maketitle

\section{Motivation}
With the increase of complexity of the SMT solver \si, soundness gets a major
concern.  For satisfiable formulas, the solver can generate a model that
should satisfy all input formulas.  Checking this becomes hard when the input
contains quantifiers.  For unsatisfiable formulas, the solver can deliver a
proof of unsatisfiability, i.\,e., a derivation of \texttt{false} from the
input formulas.  This proof should contain all the steps needed to show
inconsistency of the current set of formulas.  To achieve this, a proof system
has to be given.  This system, however, should be as close to the operations
of the solver as possible.  Unfortunately, tracking every step of the solver
becomes challenging as the resulting proof might quickly grow to a size that is
too big to keep in memory.

In this document, we explain the proof system of \si.  This proof
system completely captures the inferences done by \si at an adequate
level while keeping a reasonably small memory overhead.  The main
design goals of the system is the possibility to reconstruct the proof
in another verification system.

\section{Proofs in \si}

The SMT solver \si works in three phases.  In the first phase an input
formula is rewritten into a normal form, simplifying some terms.  This
phase uses only equality and equivalence rewrites recursively on the
whole formula and produces an equivalent formula.

The second phase splits the simplified formula into clauses and
introduces tautologies to define auxiliary literals.  We call the clauses
created in this phase the input clauses.

The third and last phase is a resolution-based proof that uses the
input clauses and theory lemmas to proof the empty clause.  This
concludes the proof.

In this section we present the three phases, starting with the last
phase, which forms the outermost layer of the resulting proof.

\subsection{Resolution Proofs}
\label{reslayer}

A resolution proof is encoded using a resolution function \verb+res+,
that takes as input an atom $p$ and two proofs for two clauses $C_1$
and $C_2$ and returns a proof for the clause $(C_1\setminus\{p\})
\cup (C_2 \setminus\{\lnot p\})$.  The clauses are sets of literals
and represents the fact that one of these literals must be true.  A
literal is either an atom $p$ or a negated atom $\lnot p$. In \si
proofs the atoms are arbitrary SMT-LIB formulas.

The pivot atom $p$ of the resolution is the firsts argument, to make
proof checking easier.  This pivot literal occurs positive in the
first clause (second argument) and negatively in the second clause
(given as third argument).  The working with clauses $C_1,C_2$ they
must be treated as sets, in particular, duplicated literals are
automatically omitted.  We use the concrete syntax \texttt{( + $p_1$ -
  $p_2$)} to represent clauses where \texttt{+} indicates an atom that
occurs postively and \texttt{-} indicates an atom that occurs
negatively.

Resolution proofs returned by \si are clean, i.e., no clause contains
a literal and its negation, and for every resolution step the pivot
literal really needs to occur in the input clauses.  Although, the
proven formula would still be valid without these restrictions, the
interpolation procedure require this form.

Since the proofs in \si were originally only constructed to produce
interpolants, there is a feature to cut the proof at the CNF-level.
To compute interpolants the rewrite steps that are local to a single
input formula are not needed.  Similarly, for computing unsatisfiable
cores only the used input formulas are needed, not their
transformation into clauses.  Since the resolution layer of the proofs
is sufficient for these two techniques, the proof system keeps this
separation and the interpolation and unsat core algorithm does not
need to descent into the proof of the input clauses and theory lemmas.
If, however, a user wants to retrieve a complete proof, the conversion
of the original formula into CNF is also tracked.

The base proof system of \si consists of only one rule, the resolution
rule.  Furthermore clauses created from input formulas and theory
lemmas are annotated with their proved clause and the necessary
annotations needed by the interpolation engine.  The proof of the lemma
itself or the transformation of the input formula into clauses can be
omitted and replaced by oracle steps.

An input clause is represented by an annotated term with the annotation
\verb+:cnf+.  This annotation can be followed by the name of the input
formula, provided the input formula has the \verb+:named+ attribute
annotated.  In the simplest form, the clause is proved by a oracle
axiom, and the annotation is put directly into the axiom.  When
tracking the CNF conversation, the annotation of the clause is around
a term that describes the proof of this clause from one of the input
formulas.  This annotation also includes a \verb+:proves+ annotation
with the clause using the concrete syntax described above.

Similarly theory lemmas are annotated terms with a lemma annotation,
e.\,g., \texttt{:CC}, \texttt{:LA}, etc.  To this label some
annotation is attached that helps to reconstruct the proof.  The
lemmas can either be an oracle axiom, or they can be fully explained
using low-level proof axioms, depending on the proof mode.  Some
theories do internal literal propagation and they can generate complex
clauses for the DPLL engine.  These complex lemmas are already split up
via a resolution chain into simple lemmas.

\subsection{Formula Transformation and Simplification}
\label{simplayer}

This section describes the intermediate proof format describing how
input formulas are normalized based on equality rewrites.  This proof
shows the equivalence of an input formula with a simpler formula.  These
kind of proofs are only present with proof-level equal to full.

\paragraph{Lifting equalities.}  To recursively rewrite a formula
\si uses the \textsc{congruence} and \textsc{quant} rule to lift
equalities from subterms.  Since all logical connectives in SMT-LIB
with the exception of quantifiers are Boolean functions, the
congruence rule can also be used for them.  For quantified formulas a
\textsc{quant} rule serves the same purpose.  Further there are the
rules \textsc{refl} and \textsc{trans} that proof reflexivity and
transitivity.

\[
\begin{array}{c}
\inferrule*[left=refl]{}{t = t}\qquad
\inferrule*[left=trans]{t_1 = t_2 \\ t_2 = t_3}{t_1 = t_3}\\[6pt]
\inferrule*[left=cong]{t = f(\dots t_i \dots) \\ t_i = t'_i}{t = f(\dots t'_i \dots)}\qquad
\inferrule*[left=quant]{F = G}{\exists/\forall x\ F = \exists/\forall x\ G}
\end{array}
\]

These rules are represented in SMTLIB as functions
\begin{verbatim}
:funs ((@trans @Proof @Proof @Proof :left-assoc)
       (@cong  @Proof @Proof @Proof :left-assoc)
       (@exists @Proof @Proof)
       (par (A) @refl A @Proof))
\end{verbatim}

The function \verb+@refl+ takes as argument a term $t$ and returns a
proof for $t=t$.  It is mainly used in the first argument of
\verb+@cong+ to indicate the rewritten function application.  The
functions \verb+@trans+ and \verb+@cong+ take as arguments two proofs
for the terms as specified in the rules above and return a proof for
the resulting goal, which can easily be computed.  The function
\verb+@quant+ takes a proof for $F=G$.  To reconstruct the quantifier
and the variables \verb+((Sort x_1) ... (Sort x_n))+ they are added as
an annotation to the argument.  It returns the proof for the exists
equality.

\paragraph{Rewrite axioms.}  The \textsc{rewrite} axiom introduces a
new equality $t_1=t_2$ where side conditions for $t_1$ and $t_2$
ensure that the equality is true.  They are introduced by a function
\verb+@rewrite+ that takes the equality $t_1=t_2$ and
returns a proof of the equality.

\begin{verbatim}
:funs ((@rewrite bool @Proof))
\end{verbatim}

The equality is annotated by the rewrite rule, which explains why
$t_1$ and $t_2$ should be equal. In the proof tree they appear as

\begin{verbatim}
  (@rewrite (! (= t1 t2) :rewrite-rule))
\end{verbatim}

where \texttt{:rewrite-rule} is the name of one of the rules listed in
the remaining section.


\paragraph{Expanding definitions.}  The rule \texttt{:expandDef} justifies
the expansion of a defined function.  Let $f(\overline{t})$ be the
application of $\overline{t}$ to the function named $f$, and
$d[\overline{t}]$ be the definition of $f$ where the free variables are
substituted by the corresponding terms.  Then, this rule justifies the
replacement of $n(\overline{t})$ by its definition.

\begin{equation}
f(\overline{t}) = d[\overline{t}]
\text{ where $d$ is the defintion of $f$} \tag{expandDef}
\end{equation}

Some internal functions are also defined as defined functions,
e.\,g., the $abs\ x$ function is defined as $(ite\ (<\ x\ 0)\ (-\ x)\ x)$. Below is an example proof using this definition.
\begin{verbatim}
(@rewrite (! (= (abs (- z)) (ite (< (- z) 0) (- (- z) (- z))))
             :expandDef))
\end{verbatim}

\paragraph{Expanding $n$-ary function applications.}  \si expands function
applications that use associativity, chainability, or the pairwise attribute.
The expansion transforms an application of a left-associative function $f$ as follows.

\begin{equation*}
  (f\ t_1\ t_2 \cdots t_n) = (f\ (\ldots (f\ t_1\ t_2)\ \ldots)\ t_n)
  \text{ where $n > 2$, $f$ left-assoc.}
  \tag{expand}
\end{equation*}
Similarly, for a right associative function,
\begin{equation*}
  (f\ t_1\ t_2 \cdots t_n) = (f\ t_1\ \ldots (f\ t_{n-1}\ t_n)\ldots)
  \text{ where $n > 2$, $f$ right-assoc.}
  \tag{expand}
\end{equation*}
Finally for a chainable predicate,
\begin{equation*}
  (p\ t_1\ t_2 \cdots t_n) = (and\ (p\ t_1\ t_2) (p\ t_2\ t_3) \ldots (p\ t_{n-1}\ t_n))
  \text{ where $n > 2$, $p$ chainable.}
  \tag{expand}
\end{equation*}

Note that \si does not expand all such functions; for example, it
keeps $n$-ary disjunctions, conjunctions, and implications.

\paragraph{Equality simplification.}
This set of rules justifies the simplification of an $n$-ary equality.  The
result depends on the simplification.  In general, it will be an equality with
up to $n$ arguments or a single term.  \si currently does the following
equality simplifications.
\begin{itemize}
\item Remove duplicated terms from the equality.  If the equality only
  contains duplicates, simplify to \verb+true+.
\item Simplify numeric equalities with different constants.
\item Simplify Boolean equalities:
  \begin{itemize}
  \item Simplify equalities containing \verb+true+ and \verb+false+ to
    \verb+false+.
  \item Simplify equalities containing \verb+true+ into conjunctions.
  \item Simplify equalities containing \verb+false+ into disjunctions.
  \item Finally convert binary Boolean equality to \verb+xor+.
  \end{itemize}
\end{itemize}

Equality simplification is split into several rules to ease proof validation.
\begin{align}
  (=\ t_1 \cdots t_n) &= false
  \quad \text{where some $t_j=true$ and some $t_k=false$}
  \tag{trueNotFalse}\\
  (=\ t_1 \cdots t_n) &= false
  \quad \text{where some $t_j$ and $t_k$ are distinct numeric constants}
  \tag{constDiff}\\
  (=\ t_1 \cdots t_n) &= (not\ (or\ \dots(not\ t_{i'})\dots))
  \quad \text{\begin{tabular}{l}where some $t_j = true$ and
      the $t_i'$ \\
      are the terms in the same order\\
      with $true$ and duplicates removed
    \end{tabular}}
  \tag{eqTrue}\\
  (=\ t_1 \cdots t_n) &= (not\ (or\ \dots t_{i'} \dots))
  \quad \text{\begin{tabular}{l}where some $t_j = false$ and
      the $t_i'$ \\
      are the terms in the same order\\
      with $false$ and duplicates removed
    \end{tabular}}
  \tag{eqFalse}\\
  (=\ t \cdots t) &= true
  \quad\text{where all $t$ are the same}
  \tag{eqSame}\\
  (=\ t_1 \cdots t_n) &= (=\ \dots t_{i'} \dots)
  \quad\text{\begin{tabular}{l}where $t_{i'}$ are the terms in the same\\
      order with repeated terms removed\end{tabular}}
  \tag{eqSame}\\
  (=\ t_1 \cdots t_n) &= (not\ (or\ (not\ (=\ t_1\ t_2)\dots(not\ (t_{n-1}\ t_n))
  \quad\text{where $n > 2$}
  \tag{eqBinary}\\
  (=\ t_1\ t_2) &= (not\ (xor\ t_1\ t_2)) \quad\text{where $t_1,t_2$ are Boolean}
  \tag{eqToXor}
\end{align}

For (eqTrue) resp. (eqFalse), in the case that there is only one
$t_i'$ the equality is rewritten to $t_i'$ resp. $(not\ t_i')$ instead.
The last rule is used to convert an $n$-ary equality into a
conjunction of binary equalities.  Note that we represent the
conjunction as a negated disjunction as is done in the canonical form
used by \si.

\paragraph{Distinct simplification.}
This set of rules is similar to the equality simplification rules.  It
contains axioms for the following cases.
\begin{itemize}
\item Simplify Boolean distinct-applications with more than two terms to
  \verb+false+.
\item Convert binary Boolean distinct-applications to \verb+xor+.
\item Simplify distinct-applications containing the same element multiple
  times to \verb+false+.
\end{itemize}

\begin{align}
  (distinct\ t_1 \cdots t_n) &= false
  \quad \text{where $n \geq 3$ and $t_i$ are boolean}
  \tag{distinctBool}\\
  (distinct\ t_1\ t_2) &= (xor\ t_1\ t_2)
  \quad \text{where $t_1,t_2$ are boolean}
  \tag{distinctToXor}\\
  (distinct\ \cdots t \cdots t \cdots) &= false
  \quad \text{where some $t$ occurs twice}
  \tag{distinctSame}\\
  (distinct\ t_1 \cdots t_n) &= (not\ (or\ \dots (=\ t_i\ t_j)\dots))
  \quad\text{where $n \geq 2$, $1 \leq i < j \leq n$}
  \tag{distinctBinary}
\end{align}
The last rule is used to convert distinct applications into negated
binary equalities.  In this case every term must be compared to every
other term.  For $n=2$ the $or$ is omitted.

\paragraph{Xor simplification.}
This set of rules simplifies xor with \verb+true+ or \verb+false+ and
pulls negation outside of the xor.  The first three rules apply
equally if the arguments are swapped.

\begin{align}
  (xor\ false\ t_2) &= t_2
  \tag{xorFalse}\\
  (xor\ true\ t_2) &= (not\ t_2)
  \tag{xorTrue}\\
  (xor\ (not\ t_1)\ t_2) &= (not\ (xor\ t_1\ t_2))
  \tag{xorNot}\\
  (xor\ (not\ t_1)\ (not\ t_2)) &= (xor\ t_1\ t_2)
  \tag{xorNot}\\
  (xor\ t\ t) &= false
  \tag{xorSame}
\end{align}

\paragraph{Negation simplification.}  \si simplifies negation to prevent
double negation and negations of \verb+true+ or \verb+false+.
\begin{equation}
  \begin{aligned}
    (not\ false) &= true\\
    (not\ true) &= false\\
    (not\ (not\ F)) &= F
  \end{aligned}
\tag{notSimp}
\end{equation}

\paragraph{Disjunction simplification.}  \si simplifies disjunctions by removing
duplicates or falsety and simplifying trivial tautologies to $true$.  We
justify these steps by two axioms.
\begin{align}
  (or\ \cdots true \cdots) &= true \tag{orTaut}\\
  (or\ t_1 \cdots t_n) &= (or \cdots t_i \cdots)
  \text{\begin{tabular}{l}where right hand side contains the terms in same\\
      order with duplicates and false removed\end{tabular}}
  \tag{orSimp}
\end{align}
For (orSimp), if the or would contain only one element, the right hand
side is just this element.  If the or would contain no element, the
right hand side is $false$.

\paragraph{If-then-else simplification.}  \si applies trivial Boolean
simplification to if-then-else terms where one of the arguments is
$true$ or $false$.  These simplifications are again justified by
axioms.
\begin{align}
  (ite\ true\ t_1\ t_2) &= t_1 \tag{iteTrue}\\
  (ite\ false\ t_1\ t_2) &= t_2 \tag{iteFalse}\\
  (ite\ t_0\ t\ t) &= t \tag{iteSame}\\
  (ite\ t_0\ true\ false) &= t_0 \tag{iteBool1}\\
  (ite\ t_0\ false\ true) &= (not\ t_0) \tag{iteBool2}\\
  (ite\ t_0\ true\ t_2) &= (or\ t_0\ t_2) \tag{iteBool3}\\
  (ite\ t_0\ false\ t_2) &= (not\ (or\ t_0\ (not\ t_2))) \tag{iteBool4}\\
  (ite\ t_0\ t_1\ true) &= (or\ (not\ t_0)\ t_1) \tag{iteBool5}\\
  (ite\ t_0\ t_1\ false) &= (not\ (or\ (not\ t_0)\ (not\ t_1))) \tag{iteBool6}
\end{align}

\paragraph{Removing Annotations.}  This axiom justifies the equality
between \verb+F+ and \verb+(! F :annotations)+, i.\,e., the semantic
equivalence of these terms.
\begin{equation}
  (!\ F\ :\!annotations) = F
  \tag{strip}
\end{equation}

\paragraph{Normalizing arithmetic expressions.}
\si uses a canonical form for affine linear expressions.
\[
\cf(c_1t_1 + \cdots + c_nt_n + c_0) := (+\ (*\ c_1\ t_1)\ \cdots\ (*\ c_n\ t_n)\ c_0)
\]

Here $c_i$ are rational constants in their canonical form, i.e.,
either $m$, $(-\ m)$, $(/\ m\ n)$, $(/\ (-\ m)\ n)$, with $m$ numeral
for integer arithmetic and $m,n$ decimals ending with $.0$ for real
arithmetic and if $n$ occurs, $m$ and $n$ must not have common
divisors and $n > 2$. The $t_i$ are terms not starting $+,*,/,-$ and
they may not appear twice.  For real arithmetic an integer term $t_i$
must be wrapped in $to\_real$.  The ordering of the $(*\ c_i\ t_i)$
terms is arbitrary but consistent throughout the proof.  If $c_i$ is
$1$, the multiplication is omitted.  If $c_i$ is $-1$, the
corresponding entry is just $(-\ t_i)$.  The value $c_i$ must not be
zero.  If $c_0$ is zero it is omitted unless $n=0$.  The $+$ is
omitted if it has only one argument.

The canonical form $\cf(t)$ of a term $t$ is achieved by moving
multiplicative constants before the term and moving the divisor into
the constant for division.  For addition, the constants for the same
term are added together.  Usual arithmetic on rational numbers is
performed to the constants.

As example, consider $t_1 = (+\ (*\ 3\ x)\ (*\ 2\ y))$ and $t_2 =
(+\ (*\ (- 3)\ x)\ y\ 1)$.  These terms are in canonical form. The
canonical form $\cf(t_1+t_2)$ is $(+\ (*\ 3\ y)\ 1)$ as the factors of
$x$ cancel out.  The canonical form $\cf(-t_2)$ is
$(+\ (*\ 3\ x)\ (-\ y)\ (-\ 1))$ or $(+\ (-\ y)\ (*\ 3\ x)\ (-\ 1))$
as the order of the terms $x$ and $y$ is not fixed.


\begin{equation}
  \begin{aligned}
  (+\ t_1 \cdots t_n) &= \cf(t_1+\dots+t_n)\\
  (-\ t_1 \cdots t_n) &= \cf(t_1-\dots-t_n)\\
  (*\ t_1 \cdots t_n) &= \cf(t_1 \cdots t_n)\\
  (/\ t_1 \cdots t_n) &= \cf(t_1 / (t_2\cdots t_n))\\
  (to\_real\ t_1) &= \cf(to\_real\ t_1)
  \end{aligned}
  \tag{canonicalSum}
\end{equation}

In these rules the terms $t_1,\dots,t_n$ must be already in canonical form.\\
For multiplication all but one $t_i$ must be a constant and
for division all but the first $t_i$ must be a constant.
For $to\_real$, the canonical form pushes the function $to\_real$ into
the $t_i$ and converts all integer constants to real constants.

The comparison operators are normalized to less equal with second argument 0.
\begin{align}
  (<=\ t_1\ t_2) &= (<=\ \cf(t_1-t_2)\ 0) \tag{leqToLeq0}\\
  (<\ t_1\ t_2)  &= (not\ (<=\ \cf(t_2-t_1)\ 0)) \tag{ltToLeq0}\\
  (>=\ t_1\ t_2) &= (<=\ \cf(t_2-t_1)\ 0) \tag{geqToLeq0}\\
  (>\ t_1\ t_2)  &= (not\ \cf(<=\ (t_1-t_2)\ 0)) \tag{gtToLeq0}
\end{align}

\paragraph{Arithmetic simplification.}  Arithmetic comparisons
can with constants can be trivially simplified
\begin{align}
  (<=\ c\ 0) &= true  \quad \text{where $c \leq 0$}\tag{leqTrue}\\
  (<=\ c\ 0) &= false \quad  \text{where $c > 0$}\tag{leqFalse}
\end{align}

\paragraph{Divisible rewrite.}  A divisible term
\verb+((_ divisible n) t)+ is rewritten into the equivalent term
\verb+(= t (* n (div t n)))+.  This rule can be used to
removes the divisible operator from the formula.
Furthermore, if $t$ is constant, it can be simplified.
\begin{equation}
  \begin{aligned}
    ((\_\ divisible\ 1)\ t) &= true\\
    ((\_\ divisible\ n)\ c) &= true \quad \text{where $n$ divides $c$}\\
    ((\_\ divisible\ n)\ c) &= false \quad \text{where $n$ does not divide $c$}\\
    ((\_\ divisible\ n)\ t) &= (=\ t\ (*\ n\ (div\ t\ n)))
  \end{aligned} \tag{divisible}
\end{equation}

\paragraph{Division rewrites.}  Integer division can be simplified if either
the divisor is $1$ or $-1$, or the dividend and the divisor are constant.  \si
uses different rewrite rules for these.
\begin{align}
  (div\ t\ 1) &= c \tag{div1}\\
  (div\ t\ (-\ 1)) &= \cf(-t) \tag{div-1} \\
  (div\ c_1\ c_2) &= \cf(sgn(c_2) \lfloor c_1/|c_2| \rfloor) \quad\text{where $c_2\neq 0$}\tag{divConst}
\end{align}
Here $sgn(c_2)$ stands for the signum function (1 for $c_1>0$, -1 for $c_1 < 0$).
While for positive $c_2$ the division function rounds toward negative
infinity, the SMTLIB standard specifies that $(div\ c_1\ (- c_2)) =
(-\ (div\ c_1\ c_2))$, which explains the cumbersome definition.


\paragraph{Modulo rewrites.}  This axiom justifies the rewrite of
\verb+(mod x y)+.  The result of the rewrite depends on the values of
\verb+x+ and \verb+y+.  If \verb+y+ is either $1$ or $-1$, the result is 0, if
\verb+x+ is constant, and \verb+y+ is a constant different from $0$, \si
replaces the modulo by the correct value.  Otherwise, if \verb+y+ is a
constant different from $0$, the modulo is rewritten into
\verb+(- x (* y (div x y)))+.  The rules mimic the SMTLIB semantic of the
Euclidian definition of div and mod.
\begin{align}
  (mod\ t\ 1) &= 0 \tag{div1}\\
  (mod\ t\ (- 1)) &= 0 \tag{div-1} \\
  (mod\ c_1\ c_2) &= \cf(c_1 - |c_2|\lfloor c_1/|c_2| \rfloor)
  \quad\text{where $c_2\neq 0$}
  \tag{moduloConst} \\
  (mod\ t_1\ c_2) &= \cf(t_1 - c_2 (div\ t_1\ c_2)) \quad\text{where $c_2\neq 0$} \tag{modulo}
\end{align}
For $c_2 = 0$ the rewrite rule would not be sound as per standard $mod$ must behave like an uninterpreted function.

\paragraph{Integer injection.}  The \verb+to_int+ operator can be used to
convert a real term into an integer.  The SMTLIB semantic describes this
conversion as the standard floor operation on reals.  If this is applied to a
constant, \si replaces the application by the result.
\begin{equation}
  (to\_int\ c) = \cf(\lfloor c \rfloor) \quad\text{where $c$ is constant} \tag{toInt}
\end{equation}

\paragraph{Array rewrites.}  The theory of arrays contains several constructs
that can be the target of rewrites.  \si implements the following rewrites for
arrays:
\begin{itemize}
\item Static store-over-store:  If a store overwrites the value of a directly
  adjacent store term, the inner store term is removed.
  \begin{equation}
    (store\ (store\ a\ i\ v_1)\ i\ v_2) = (store\ a\ i\ v_2)
    \tag{storeOverStore}
  \end{equation}
\item Static select-over-store: If the select-over-store axiom can be
  statically evaluated, \si replaces the application of the term by
  its conclusion.  Static evaluation can be done if the index terms
  are known to be equivalent or distinct.  Since \si does not include
  congruence closure in the simplification phase, it only simplifies
  if the index terms are syntactically equal or numerical.  For
  disequality, the difference must be a constant or, in the integer
  case, a term of the form $\sum c_it_i + c$ where $gcd(c_i)$ does not
  divide $c$.
  \begin{equation}
    \begin{aligned}
      (select\ (store\ a\ i\ v)\ i) &= v\\
      (select\ (store\ a\ t_1\ v)\ t_2) &= (select\ a\ t_2) \quad\text{where $t_1\neq t_2$ holds trivially}\\
    \end{aligned}\tag{selectOverStore}
  \end{equation}
\item Store rewrite:  In the array theory it is possible to have store terms
  that only describe values for the base array.  In this case, the store term
  can be rewritten into a select.
  \begin{equation}
    \begin{aligned}
      (=\ (store\ a\ i\ v)\ a) &= (=\ (select\ a\ i)\ v)\\
      (=\ a\ (store\ a\ i\ v)) &= (=\ (select\ a\ i)\ v)
    \end{aligned}\tag{storeRewrite}
  \end{equation}
\end{itemize}

\subsection{CNF conversion}
\label{cnflayer}
After normalization and simplification, \si produces CNF from the modified
input formula.  The proof rules described before justify the equivalence of
the input assertion and the canonical form.  The rules in this section justify
the transformation of the canonical form into an equivalent CNF.  The
basic operations performed during this process are creation of literals from
the leaves of the Boolean part of the term, structural splitting of the
formula, and introduction of auxiliary atoms for a Plaisted--Greenbaum- or
Tseitin-style encoding of the input formula.

The produced clauses use literals with meaning, i.e., the literals are
SMT-LIB formulas.  It is important to note that the DPLL engine
ignores the meaning of the literals.  For some literals the theories
will ensure that truth values for these literals are consistent, for
other literals, tautologies in the form of clauses need to provide the
meaning.  The latter tautologies are added during the CNF conversion.

\paragraph{Structural Splitting.}
If the input formula is given as CNF, it is useful to detect this and
create clauses that correspond directly to the formula instead of just
providing a full Tseitin-encoding of the input.  For example if the
top-level symbol of a formula is an \smtlib{and}, the subformulas can
be converted separately into CNF.  Othere solvers use splitting rules to
explain these steps, e.g.,

\begin{mathpar}
  \inferrule*[left=and-,right={$0\leq j\leq n$}]{(\smtlib{and}\ t_0\ldots t_n))}{t_j)}
\end{mathpar}

We prefer to stick to resolution calculus, since then we can just
reuse the Tseitin-style tautology.  For the Tseitin encoding we
already have the tautology axiom \textsc{and-}:

\begin{mathpar}
  \inferrule*[left=and-,right={$0\leq j\leq n$}]{}{\{\lnot (\smtlib{and}\ t_0\ldots t_n), t_j \}}
\end{mathpar}

Then the rule mentioned above can be written with a single resolution
step, simplifying the number of rules we need dramatically.

\begin{mathpar}
  \inferrule*[left=res] {\{(\smtlib{and}\ t_0\ldots t_n)\} \quad
  \inferrule*[left=and-,right={$0\leq j\leq n$}]{}{\{\lnot (\smtlib{and}\ t_0\ldots t_n), t_j \}}}{\{t_j\}}
\end{mathpar}

Indeed an equivalent proof could be produced by just adding the
corresponding literals to the DPLL engine and letting DPLL apply unit
propagation.  However we feel that its better to do these steps in the
pre-processing phase and produce fewer clauses that would otherwise
burden the DPLL engine for the remaining run.

In this phase, nested \smtlib{or} terms (or other terms that are
disjunctive in nature) are also ``flattened'' by repeatedly resolving
with the \textsc{or-} axiom.

\begin{mathpar}
  \inferrule*[left=or-]{}{\{\lnot (\smtlib{or}\ t_0\ldots t_n), t_0, \dots t_n \}}
\end{mathpar}

We avoid flattening \smtlib{or} terms shared between multiple clauses.
Instead we keep the literal as it is and use Tseitin encoding to
provide the meaning.


\paragraph{Building Literals.}
After splitting the term-DAG into clauses, every term in every clause is
transformed into a literal\footnote{This process sometimes is called
  \emph{internalization}.}.  This step might slightly change the term
representation due to implicit application of symmetry or associativity
axioms, or might even simplify the term to \texttt{false} if theory reasoning
allows further simplification, e.\,g., in the case of linear equalities over
the integer (e.\, g., $2x=1$).  We justify this step by another rewrite rule.
\[
\inferrule*[left=intern,right={$F\equiv F'$}]{ }{F = F'}
\]
The proxy literals used in the Plaisted--Greenbaum-CNF encoding are
named directly after the sub-formula and therefore no rewriting step
is needed.

\paragraph{Building clauses.}
A literal in \si is represented in the proof by its SMTLIB term.
When creating equality literals in congruence closure we first check for
trivial equalities:
An equality $t_1=t_2$ is trivially $true$ if $t_1$ and $t_2$ are identical.
If the sort is integer or real, it is trivially $false$ if $t_1 - t_2$ is
a non zero constant, or in the integer case if it is of the form
$\sum_{i>0} c_i t_i + c_0$ and the constant $c_0$ does not
divide the $gcd(c_1,\dots,c_n)$.
Furthermore the equality literals are normalized, i.e., the sides of the
equality may be swapped, e.g., if this results in a previously created
literal.
\begin{align}
  (=\ t_1\ t_2) &= true  && \text{if trivially true}\tag{intern}\\
  (=\ t_1\ t_2) &= false && \text{if trivially false}\tag{intern}\\
  (=\ t_1\ t_2) &= (=\ t_2\ t_1) && \text{if that equality was created earlier}
  \tag{intern}
\end{align}

When creating equality literals in linear arithmetic, the first step
is to divide the affine term $\sum_{i>0} c_i t_i + c_0$ by
$gcd(c_1,\dots,c_n)$, the gcd of the coefficients of the $t_i$ terms.
For rationals, this is defined such that dividing by the gcd results
in coprime integer coefficients.  The sign is normalized, so the term
can be negated.  This may result in a negated $<$ literal instead of a
$<=$ literal.  For integer inequalities, the constant $c_0/gcd$ is
then rounded to the nearest integer, or if it was an equality, the whole
equality can be simplified to false, if $c_0/gcd$ is not an integer.
\begin{align}
  (=\ t\ 0) &= \begin{cases} false & \text{if trivially false}\\
    (=\ \cf(t/gcd)\ 0) \\
    (=\ \cf(-t/gcd)\ 0)
  \end{cases}
  \tag{intern}\\
  (<=\ t\ 0) &= \begin{cases} 
    (<=\ \cf(t/gcd)\ 0) \\
    (not\ (<\ \cf(-t/gcd)\ 0)) &\text{(real case)}\\
    (not\ (<=\ \cf(-t/gcd + 1)\ 0))& \text{(integer case)}
  \end{cases}
  \tag{intern}
\end{align}


\paragraph{Tautologies.}
For some introduced terms or literals a corresponding tautology is
created during the transformation into CNF.  These tautologies are
clauses that are annotated with the kind of the tautology.

Table~\ref{tab:tautforms} lists the different kinds of tautologies present
in \si.  Here $F$ denotes formulas, $t$ denotes terms,
and $t_F$ denotes the term corresponding to $F$\footnote{In the proof returned
  by \si, $t_F$ and $F$ are equal.  The distinction is only done internally
  since $F$ is a Boolean term handled by the DPLL core and $t_F$ is the term
  used by congruence closure.}.
\si internally collects the disjunctive parts of the individual formulas.

The \texttt{termITE} tautology defines the meaning of non-boolean
$ite$ terms.  It can also be used for nested $ite$ terms, i.\,e., when
the then- or else-part of the ite is an ite again.  We collect a
literal for every condition $F_i$ on the path from the $ite$ term to
the subterm $t$ and include it negatively or positively depending on
whether term $t$ appears in the second or third argument of the $ite$
term.  We do not necessarily unfold all nested $ite$ terms, i.\,e., the
subterm $t$ can be another $ite$ term, e.\,g., because it occurs
multiple times in the formula.
For the \texttt{termITEBound} the $min()$ and $max()$
functions are computed at pre-processing time.  These axioms are only
instantiated if all branches in the nested ite term only differ by
constants.
\begin{table}[htbp]
  \begin{tabular}{l|l}
    Kind & Clause\\\hline
    trueNotFalse & $\{\neg(\smtlib{= true false})\}$\\
    true+ & $\{\smtlib{true}\}$\\
    false- & $\{\neg\smtlib{false}\}$\\
    and+ & $\{(\smtlib{and}\ F_1\ \ldots\ F_n), \neg F_1, \ldots, \neg F_n\}$\\
    and- & $\{\neg(\smtlib{and}\ F_1\ \ldots\ F_n), F_i\}$\\
    or+ & $\{(\smtlib{or}\ F_1\ \ldots\ F_n), \neg F_i\}$\\
    or- & $\{\neg(\smtlib{or}\ F_1\ \ldots\ F_n), F_1, \ldots, F_n\}$\\
    imp+ & $\{(\smtlib{=>}\ F_1\ \ldots\ F_n), (\neg) F_i\}$\\
    imp- & $\{\neg(\smtlib{=>}\ F_1\ \ldots\ F_n), \neg F_1, \ldots, \neg F_{n-1}, F_n\}$\\
    iff+1 & $\{(\smtlib{=}\ F_1\ F_2), F_1, F_2\}$\\
    iff+2 & $\{(\smtlib{=}\ F_1\ F_2),\neg F_1, \neg F_2\}$\\
    iff-1 & $\{\neg(\smtlib{=}\ F_1\ F_2), F_1, \neg F_2\}$\\
    iff-2 & $\{\neg(\smtlib{=}\ F_1\ F_2),\neg F_1, F_2\}$\\
    ite+1 & $\{(\smtlib{ite}\ F_1\ F_2\ F_3),\neg F_1,\neg F_2\}$\\
    ite+2 & $\{(\smtlib{ite}\ F_1\ F_2\ F_3), F_1,\neg F_3\}$\\
    ite+Red & $\{(\smtlib{ite}\ F_1\ F_2\ F_3),\neg F_2,\neg F_3\}$\\
    ite-1 & $\{\neg(\smtlib{ite}\ F_1\ F_2\ F_3),\neg F_1, F_2\}$\\
    ite-2 & $\{\neg(\smtlib{ite}\ F_1\ F_2\ F_3), F_1, F_3\}$\\
    ite-Red & $\{\neg(\smtlib{ite}\ F_1\ F_2\ F_3), F_2, F_3\}$\\
    xor+1 & $\{(\smtlib{xor}\ F_1\ F_2), F_1,\neg F_2\}$\\
    xor+2 & $\{(\smtlib{xor}\ F_1\ F_2),\neg F_1, F_2\}$\\
    xor-1 & $\{\neg(\smtlib{xor}\ F_1\ F_2), F_1, F_2\}$\\
    xor-2 & $\{\neg(\smtlib{xor}\ F_1\ F_2),\neg F_1,\neg F_2\}$\\
    excludedMiddle1 & $\{(=\ F\ \smtlib{true}) , \neg F\}$\\
    excludedMiddle2 & $\{(=\ F\ \smtlib{false}) , F\}$\\
    termITE & $\{(\neg) F_1,\ldots,(\neg) F_n , (=\ (\smtlib{ite}\ F_1 (\smtlib{ite}\ F_2 \cdots (\smtlib{ite}\ F_n\ t\ \_)\cdots))\ t)\}$\\
    termITEBounds & $\{(\smtlib{ite}\ F\ (\smtlib{ite} \dots t_1 \dots t_n)) - max(t_i) \leq 0\}$\\
     & $\{min(t_i) -(\smtlib{ite}\ F (\smtlib{ite} \dots t_1 \dots t_n)) \leq 0\}$\\
    divLow & $\{d\cdot (\smtlib{div $x$ $d$}) - x \leq 0\}$\\
    divHigh & $\{\neg (|d| - x + d\cdot (\smtlib{div $x$ $d$})\leq 0)\}$\\
    toIntLow & $\{(\smtlib{to\_real }(\smtlib{to\_int }x)) - x \leq 0\}$\\
    toIntHigh & $\{\neg (1 - x + (\smtlib{to\_real }(\smtlib{to\_int }x))\leq 0)\}$\\
    array-store & $\{(=\ (\smtlib{select }(\smtlib{store }a\ i\ v)\ i)\ v)\}$\\
    array-diff & $\{(=\ a\ b), \neg(=\ (\smtlib{select }a\ (\smtlib{@diff }a\ b))\ (\smtlib{select }b\ (\smtlib{@diff }a\ b)))\}$\\
  \end{tabular}
  \caption{\label{tab:tautforms}Different Kinds of Tautology Clauses.}
\end{table}

\subsection{Theory Lemmas}
\label{lemmas}
Theory lemmas are tautological clauses that follow from one of the
theories.  In \si we have the theories of Congruence Closure, Linear
Arithmetic, and Arrays.  Furthermore there is a Nelson-Oppen theory
that translates equalities from congruence closure to linear
arithmetic.

In low-level proofs a lemma is indicated by annotating its proof with
the lemma annoation and the proved clause.  If low-level proofs are
not active, a lemma is created by the \verb+@lemma+ function, which
takes as argument the proved clause that is annotated with some theory
specific annotations.
\begin{verbatim}
:funs ((@lemma bool @Proof))
\end{verbatim}

\paragraph{Congruence Closure}

There are only two kinds of rules for congruence closure: transitivity
and congruence.  A transitivity proves a lemma of the form ${t_1 = t_2}
\land \cdots\land {t_{n-1}= t_n} \rightarrow {t_1 = t_n}$ and is
represented by an SMTLIB term as follows:

\begin{verbatim}
(@lemma (! (or (= t1 tn)
               (not (= t1 t2)) ... (not (= tn-1 tn)))
           :trans (t1 t2 ... tn))))
\end{verbatim}

The annotation \verb+:trans+ marks this as a transitivity lemma.  Its
annotation is the path of terms the transitivity traverses.  The
equality proved by the transitivity is between the end points of this
path.  This equality should occur positively in the clause, unless it
is trivially false, e.g. $x = x+1$ or $2x = 2y+1$ where $x,y$ are
integer.  The annotaion explains why the proved equality follows from
the other equalities and for each adjacent terms in the path the
corresponding negated equality must exists in the clause.  The
literals in the clause can appear in any order, and the arguments of
the equality literals can be swapped.

The other type of lemma proves a congruence of the form $f(t_1, \dots,
t_n)\neq f(t'_1,\dots,t'_n) \lor t_1=t_1' \lor \cdots \lor t_n=t_n'$.
It is represented very similarly by the following SMTLIB term.

\begin{verbatim}
(@lemma (! (or (= (f t1...tn) (f t'1...t'n))
               (not (= t1 t'1)) ... (not (= tn t'n)))
           :cong ((f t1...tn) (f t'1...t'n))
\end{verbatim}

The argument of the annotation is the proved congruence, which should
occur as an equality in the clause.  For each argument of the
congruent terms the equality between $t_i$ and $t'_i$ should appear
negatively in the clause, unless they are identical.  Again, the
literals in the clause can appear in any order, and the arguments of
the equality literals can be swapped.

\paragraph{Array Lemma}
\todo{cite weak equivalence paper, and const, present rules}

\begin{verbatim}
(@lemma (! (or (= (select a i) (select b j))
               (not (= i j)) ...)
  :read-over-weakeq ((= (select a i) (select b j))
                     :weakpath (i (a ... b)))))
\end{verbatim}
The negated equality $i\neq j$ is omitted if $i$ and $j$ are identical.
For any two adjacent terms in the weak path of this lemma, there must be either
(1) a corresponding negated equality in the clause, or (2) one of the term must be of
the form $(store\ a k \cdot)$ where $a$ is the other term and there is must be
a (non-negated) equality $i=k$ in the clause (i.e., the conflict guarantees $i\neq k$).
The equality $i=k$ is omitted if it is trivially false, e.g., for $k = i+1$.

\begin{verbatim}
(@lemma (! (or (= (select a i) v) ...)
  :read-const-weakeq ((= (select a i) v)
                      :weakpath (i (a ... const v)))))
\end{verbatim}
Again, for any two adjacent terms in the weak path of this lemma, there must be either
(1) a corresponding negated equality in the clause, or (2) one of the term must be of
the form $(store\ a k \cdot)$ where $a$ is the other term and there is must be
a (non-negated) equality $i=k$ in the clause (i.e., the conflict guarantees $i\neq k$).
The equality $i=k$ is omitted if it is trivially false, e.g., for $k = i+1$.
Note: For \verb+:read-const-weakeq+, if $a = (const\ v)$, the weak path
contains only one element.  This is the only reason why one can have a
path of length one.
\begin{verbatim}
(@lemma (! (or (= a b) ...)
  :weakeq-ext ((= a b)
               :subpath (a ... b)
               :weakpath (i1 (a ... b))...
               :weakpath (in (a ... b)))))
\end{verbatim}
For any two adjacent terms in the sub path of this lemma, there must be either
(1) a corresponding negated equality in the clause, or (2) one of the term must be of
the form $(store\ a i_j \cdot)$ where $a$ is the other term and there is a corresponding
weak path on index $i_j$.  For each adjecent terms $t_1,t_2$ in the weak path, there must be
(1) a corresponding negated equality in the clause, or (2) one of the term must be of
the form $(store\ a k \cdot)$ where $a$ is the other term and there is a
(non-negated) equality $i_j=k$ in the clause (i.e., the conflict guarantees $i_j\neq k$),
(3) some $i,j$ exists such that the clause contains the negated equalities
$i_k\neq i$, $i_k\neq j$, and $(select\ t_1\ i) \neq (select\ t_2\ j)$, or
(4) $t_2 = (const\ v)$ and $i$ exists such that the clause contains
$i_k\neq i$ and $(select\ t_1\ i) \neq v$ (or analogously for $t_1=(const\ v)$.
Note that in case (3) and (4) the term for which $(select t i)$ should exists, can itself
be a const term.  There is no annotation giving the terms $i,j$ in case (3) or (4); these
must be found by checking all disequalities involving $select$ terms.
Again, the equality $i=k$ is omitted if it is trivially false, e.g., for $k = i+1$ and the
disequality $i_k \neq i$ is omitted if the indices are identical.

\begin{verbatim}
(@lemma (! (or (= (const v) (const v')) ...)
  :const-weakeq ((= (const v) (const v'))
                 :subpath ((const v) ... (const v')))))
\end{verbatim}
For any two adjacent terms in the subpath of this lemma, there must be either
a corresponding negated equality in the clause, or one of the term must be of
the form $(store\ a \cdot \cdot)$, where $a$ is the other term.
\todo{This is not yet implemented exactly like this.  read-over-weakeq
  still have a strong path for i=j of length 2.  We may include some more
  trivial strong paths of length 2.}


\paragraph{Linear Arithmetic}

A linear arithmetic lemma proves the contradiction of linear
inequalites $t_1\leq 0\land \dots\land t_n\leq 0 \rightarrow false$, if
there are coefficients $c_1,\dots,c_n > 0$ such that $\sum c_it_i$ is
a negative constant.  The sum can also be zero, if at least one of the
inequalities is strict.  We also allow equalities to occur in the
conflict.

Since a theory lemma is a negated conflict, the literals occur negated
in the clause.  However a negated literal is again an inequality and
$t_1\leq 0$ can also be represented as $\neg (-t_1 <0)$, in which case
the negated literal is $(<\ -t_1\ 0)$.  In this case we use a negative
constant $c_i$, so that we can multiply $c_i$ with the term occuring
in the formula.  So if a inequality literal occurs negated in the
clause, $c_i$ must be positive, if it occurs positive in the clause
$c_i$ must be negative.  Equality literals may only occur negated in
the clause (positive in the conflict) and for them only $c_i\neq 0$ is
required.  An LA lemma is annotated by the constants $c_i$ in the same
order as the literals in the lemma.  For example if $t_1 + t_2 - t_3 =
0$, the following lemma explains why $t_1 < 0 \land t_2 = 0 \land t_3
>= 0$ is unsatisifiable.
\begin{verbatim}
(@lemma (! (or (not (< t1 0)) (not (= t2 0)) (< t3 0))
  :LA (1 1 (- 1))))))
\end{verbatim}

For integer arithmetic, if a literal occurs positively in the clause as
as $(<=\ t_i\ 0)$, one needs to take care that the negation is
$(<= (-t_i+1)\ 0)$, so the term $c_i(t_i - 1)$ is added instead
of $c_i t_i$.  This is also the case in mixed integer and real arithmetic,
if the literal contains only integer variables.

A positive equality literal can only appear in a trichotomy lemma.
This lemma explains $t \leq 0 \rightarrow t < 0 \lor t=0$ and has the form
\begin{verbatim}
(@lemma (! (or (< t 0) (= t 0) (not (<= t 0))) :trichotomy))
\end{verbatim}
The literals may appear in any order in the clause.  For integer
arithmetic the literals never use $<$ and the lemma has the form.
\begin{verbatim}
(@lemma (! (or (<= "t+1" 0) (= t 0) (not (<= t 0))) :trichotomy))
\end{verbatim}
Here \verb|"t+1"| stands for the canonical form of $t+1$.

There are no cut lemmas in \si.  Instead \si uses extended branches on
linear integer terms.  Branching is not part of any theory lemma and
is handled by the resolution proof.

\paragraph{Nelson-Oppen Combination}

These lemmas are a bit special as they are created by linear
arithmetic and by congruence closure to propagate equalities to the
other theory.  We use slightly different representation of equalities
in these theories.  As explained earlier in congruence closure an
equality $t_1=t_2$ is represented as $(=\ t_1\ t_2)$,
while in linear arithmetic it is $(=\ \cf_{gcd}(t_1-t_2)\ 0)$.
To connect these literals, we use Nelson-Oppen theory lemmas of the form.
\begin{verbatim}
(@lemma (! (or (= t1 t2) (not (= "t1-t2" 0))) :EQ))
\end{verbatim}
This propagates an equality from linear arithmetic to congruence
closure.  A similar lemma where the literals occur in the opposite
polarity is created to propagate an equality from congruence closure
to linear arithmetic.

\section{Implementation}
After presenting the set of rules used by \si, we now describe some
implementation issues that describe how to compactly represent the
proof in memory or as text.

\subsection{DAGs and letted terms}
In \si, terms are represented as DAGs, i.e., a term object like a
function application contains references to its subterms.  These
references can be shared with other functions.  This sharing can make
a proof DAG be exponentially more succinct than its corresponding
tree.  We force this sharing rigorously by only creating a term if a
syntactically identical term does not already exists.

The proof DAG can lead to complications with the $let$ operator, where
the same term variable (and thus any term containing it) can have
different meaning depending on which $let$ binds this term variable,
i.e., where in the proof DAG it appears.  This can be avoided either
by using a different term variable object for every let, or by
avoiding let altogether.  In \si we choose the latter and expand all
$let$ terms after initial parsing.  We consider the $let$ syntactic
sugar and consider different let terms that expand to the same proof
DAG to be identical.  The expansion process simply replaces any
reference to the let variable to the reference of the term that is
bound to it.  This does not create more terms, as all previous
occurences of references to the let variable are only changed to
references to the shared term.

When working on term DAGs, it is very important to keep a cache of
already visited terms and to perform the work only once for each term,
in particular, one must only iterate once through the subterms of a
term.  When printing out DAGs, we reintroduce lets for every shared
term that is not a constant.

For proof terms this means that although the simplification of a
formula and the splitting into sub-clauses is only done once, the
proof can be referenced multiple times in the proof DAG, e.g., if the
clause was used in several resolution steps.  Moreover, we often
include the same complicated term multiple times in rewrite rules,
when rewriting one of the surrounding terms in multiple steps.  These
are also represented by references to the same object, and it is
important to not iterate them more than once.


\section{Proof Terms in \si}
Proofs are represented as terms of sort \verb+@Proof+ in \si.  Note that the
\verb+@+ is part of the name of the sort to prevent unintentional clashes with
user-defined sorts since \verb+@+ and \verb+.+ are reserved for solvers in the
SMTLIB standard.

There are several rules to convert a Boolean formula into a proof.  In the
following we will show these rules and discuss their annotations.

\paragraph{Showing Results.}  The rules in SMTLIB format produce an implicit
result.  To simplify the work for the interpolator, \si appends the
results of CNF conversion and lemmas to their proof.

\section{Example Proof}
In this section, we show the proof produced by \si for the
formula $2x=z \land 2y + 1 = z$ where the variables $x,y,z$ are integer
variables on various levels.

On the clauses level, the proof just gives the results of the CNF
conversion and the produced theory lemmas.  The result of the CNF
conversion are two unit clauses:
\begin{verbatim}
(@clause (! (@asserted (= (+ z (* (- 2) x)) 0)) :input))
(@clause (! (@asserted (= (+ (* 2 y) (* (- 1) z) 1) 0)) :input))
\end{verbatim}

The solver internally generates a cut on $y-x +1 \leq 0$ and uses two
theory lemmas that show that both the cut and its negation are
inconsistent with the input clauses.  The annotation gives the
Farka\'{s} coefficients for each literal.
\begin{verbatim}
(@lemma (! (or (not (= (+ z (* (- 2) x)) 0))
               (not (= (+ (* 2 y) (* (- 1) z) 1) 0))
               (<= (+ y (* (- 1) x) 1) 0))
               :LA (1 1 (- 2))))
(@lemma (! (or (not (<= (+ y (* (- 1) x) 1) 0))
               (not (= (+ z (* (- 2) x)) 0))
               (not (= (+ (* 2 y) (* (- 1) z) 1) 0)))
               :LA (2 (- 1) (- 1))))
\end{verbatim}

The two input clauses and the two lemma clauses are then just combined by
three application of the resolution rule to obtain the clause level proof.
For brevity, we omit the pivot literals here.

\begin{verbatim}
  (@res (@res .lemma1 .lemma2) .cnf1 .cnf2)
\end{verbatim}

If proof-level is set to full, the cnf conversion is explained in more
details.  We focus here on the proof of the first clause showing
\smtlib{(= (+ z (* (- 2) x)) 0)}.  The first step is a resolution with
the \textsc{and-} tautology to extract the subformula $2x=z$ from the
asserted formula.  Then this literal is internalized to $z + -2x = 0$.
For the internalization the rewrite rule showing the equality between
these terms is used and then the \textsc{iff-} tautology is used
together with the intern rule to prove the clause $z-2x=0$ from the
input.

\begin{verbatim}
(@clause (!
 (@res 
   (@res (@asserted (and (= (* 2 x) z) (= (+ (* 2 y) 1) z)))
         (@tautology (! (or (not (and (= (* 2 x) z) (= (+ (* 2 y) 1) z)))
                            (= (* 2 x) z)) :and-)))

   (@tautology (! (or (not (= (= (* 2 x) z) (= (+ z (* (- 2) x)) 0)))
                      (not (= (* 2 x) z)) (= (+ z (* (- 2) x)) 0)) :=-2))
   (@rewrite (! (= (= (* 2 x) z) (= (+ z (* (- 2) x)) 0)) :intern)))
 :proves ((= (+ z (* (- 2) x)) 0)) :input))
\end{verbatim}

\end{document}

%% Local Variables:
%% compile-command: "pdflatex -halt-on-error proof"
%% compilation-read-command: nil
%% End:
